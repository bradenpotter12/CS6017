{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and setup \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch import Tensor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       m_label  r0c0  r0c1  r0c2  r0c3  r0c4  r0c5  r0c6  r0c7  r0c8  ...  \\\n",
       "0           48     1     1     1     1     1     1   154   255   255  ...   \n",
       "1           50     4     7    22    49    97   120   139   156   162  ...   \n",
       "2           83     1     1     1     1   255   255   255   255   255  ...   \n",
       "3           48     1     1     1     1     1   114   255   255   255  ...   \n",
       "4           54     1     1     1     1     1     1     1     1   255  ...   \n",
       "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "26232       37     1     4    83   208   255   255   161    16     1  ...   \n",
       "26233       36     1     1     1     1     1     1     1     1     1  ...   \n",
       "26234       35     1     1     1     1     1     1    77   253   255  ...   \n",
       "26235       34    43   255   255   255   255   255   255   255   255  ...   \n",
       "26236       33     1     1     1     1     1     1     1     1     1  ...   \n",
       "\n",
       "       r19c10  r19c11  r19c12  r19c13  r19c14  r19c15  r19c16  r19c17  r19c18  \\\n",
       "0         255     255     255     154       1       1       1       1       1   \n",
       "1         213     225     229     239     240     240     221     209     116   \n",
       "2         255     255     255     255     255     255       1       1       1   \n",
       "3           1       1       1       1       1       1       1       1       1   \n",
       "4         255     255     255     255       1       1       1       1       1   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "26232       1       1      16     161     255     255     208      83       4   \n",
       "26233       1       1       1       1       1       1       1       1       1   \n",
       "26234     255     255     253      77       1       1       1       1       1   \n",
       "26235      43     255     255     255     255     213       1       1       1   \n",
       "26236      23       1       1       1       1       1       1       1       1   \n",
       "\n",
       "       r19c19  \n",
       "0           1  \n",
       "1          95  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "26232       1  \n",
       "26233       1  \n",
       "26234       1  \n",
       "26235       1  \n",
       "26236       1  \n",
       "\n",
       "[26237 rows x 401 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>m_label</th>\n      <th>r0c0</th>\n      <th>r0c1</th>\n      <th>r0c2</th>\n      <th>r0c3</th>\n      <th>r0c4</th>\n      <th>r0c5</th>\n      <th>r0c6</th>\n      <th>r0c7</th>\n      <th>r0c8</th>\n      <th>...</th>\n      <th>r19c10</th>\n      <th>r19c11</th>\n      <th>r19c12</th>\n      <th>r19c13</th>\n      <th>r19c14</th>\n      <th>r19c15</th>\n      <th>r19c16</th>\n      <th>r19c17</th>\n      <th>r19c18</th>\n      <th>r19c19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>48</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>154</td>\n      <td>255</td>\n      <td>255</td>\n      <td>...</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>154</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>4</td>\n      <td>7</td>\n      <td>22</td>\n      <td>49</td>\n      <td>97</td>\n      <td>120</td>\n      <td>139</td>\n      <td>156</td>\n      <td>162</td>\n      <td>...</td>\n      <td>213</td>\n      <td>225</td>\n      <td>229</td>\n      <td>239</td>\n      <td>240</td>\n      <td>240</td>\n      <td>221</td>\n      <td>209</td>\n      <td>116</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>83</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>...</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>114</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>255</td>\n      <td>...</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26232</th>\n      <td>37</td>\n      <td>1</td>\n      <td>4</td>\n      <td>83</td>\n      <td>208</td>\n      <td>255</td>\n      <td>255</td>\n      <td>161</td>\n      <td>16</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>16</td>\n      <td>161</td>\n      <td>255</td>\n      <td>255</td>\n      <td>208</td>\n      <td>83</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26233</th>\n      <td>36</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26234</th>\n      <td>35</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>77</td>\n      <td>253</td>\n      <td>255</td>\n      <td>...</td>\n      <td>255</td>\n      <td>255</td>\n      <td>253</td>\n      <td>77</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26235</th>\n      <td>34</td>\n      <td>43</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>...</td>\n      <td>43</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>213</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26236</th>\n      <td>33</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>23</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>26237 rows × 401 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "# Create data fram with only m_label and pixel values\n",
    "df = pd.read_csv(\"ARIAL.csv\")\n",
    "df = df.drop(columns=['font', 'fontVariant', 'strength', 'italic', 'orientation', 'm_top', 'm_left', 'originalH', 'originalW', 'h', 'w'])\n",
    "# pd.set_option(\"display.max_rows\", 30, \"display.max_columns\", None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pixel_values = df.drop(columns=['m_label'])\n",
    "pixel_array = np.array(df_pixel_values)\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "pixel_array = pixel_array.astype(float)\n",
    "for i in range(len(pixel_array)):\n",
    "    for j in range(len(pixel_array[0])):\n",
    "        pixel_array[i][j] = pixel_array[i][j] / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(26237, 400)\n(26237, 1, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "Xs = pixel_array # 20 x 20 array containing the pixel values\n",
    "print(Xs.shape)\n",
    "Xs = np.reshape(Xs, (-1, 1, 20, 20))\n",
    "print(Xs.shape)\n",
    "chars = set(df['m_label'])\n",
    "uniqueChars = len(chars)\n",
    "char_to_ix = {char: i for i, char in enumerate(chars)}\n",
    "asciiValues = df['m_label']\n",
    "lst = []\n",
    "for ascii_val in asciiValues:\n",
    "    lst.append(char_to_ix[ascii_val]) # creating list of index values of each ascii char label\n",
    "\n",
    "Ys = np.array(lst) # convert list to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into testing and training sets\n",
    "Xs_train, Xs_test, Ys_train, Ys_test = train_test_split(Xs, Ys, random_state=1, test_size=0.75)\n",
    "Xs_train = torch.tensor(Xs_train, dtype = torch.float)\n",
    "Ys_train = torch.tensor(Ys_train, dtype = torch.float)\n",
    "Xs_test = torch.tensor(Xs_test, dtype = torch.float)\n",
    "Ys_test = torch.tensor(Ys_test, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_test = TensorDataset(Xs_test, Ys_test) \n",
    "tensor_train = TensorDataset(Xs_train, Ys_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        c1Out = 6 # convoluation layer 1 will output 6 \"images\": one for each filter it trains\n",
    "        c2Out = 16 # similarly for the 2nd convolution layer\n",
    "        self.conv1 = nn.Conv2d(1, c1Out, 3) #1-D input, c1Out outputs, filter size 3x3 pixels\n",
    "        \n",
    "        # (28-2)*(28 -2)*c1Out outputs\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2) #downsample 2x2 blocks to 1 value\n",
    "        \n",
    "        # 13*13*c1Out\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(c1Out, c2Out, 3) #inputs comes from conv1 , specify our #outputs, use 3x3 blocks again\n",
    "        \n",
    "        # (13-2)*(13 -2)*c2Out\n",
    "        # pool again\n",
    "        # (11/2)*(11/2)*c2Out = 5*5*c2Out\n",
    "        \n",
    "        #this is tricky.  The convolutions each shave 1 pixel off around the border, and then the\n",
    "        #max pools reduce the number of pixels by 4\n",
    "        self.pooledOutputSize = c2Out*3*3 # 16 outputs per image whose size has been reduced\n",
    "        self.fc1 = nn.Linear(self.pooledOutputSize, 120)\n",
    "        self.fc2 = nn.Linear(120, 3098)\n",
    "\n",
    "    def forward(self, x): # \"batch\" of images\n",
    "        #x is 4D tensor:  (batch size, width, height, #channels (1, grayscale image))\n",
    "        #after conv1:  (batch size, width adjusted, height adjusted, conv1 # outputs)\n",
    "        #after max pool: (batch size, width/2, height/2, conv1 # outputs)\n",
    "        # print(\"Before 1st: \" + str(x.shape))\n",
    "        # x = F.relu(self.conv1(x))\n",
    "        x = self.conv1(x)\n",
    "        # print(\"x = self.conv1(x) \" + str(x.shape))\n",
    "        x = F.relu(x)\n",
    "        # print(\"x = F.relu(x) \" + str(x.shape))\n",
    "        x = self.pool(x)\n",
    "        # print(\"Max Pool: \" + str(x.shape))\n",
    "        #split into 2 lines above\n",
    "        #x = self.pool(F.relu(self.conv1(x)))  #apply convolution filter, then run it through relu activation function\n",
    "        # x = self.pool(F.relu(self.conv2(x))) #ditto\n",
    "        x = self.conv2(x)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        # print(x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(\"after pool before flatten \" + str(x.shape))\n",
    "        #print(x.shape) #uncomment to see the size of this layer.  It helped me figure out what pooledOutputSize shoudl be\n",
    "        \n",
    "        \n",
    "        #turn the 5x5xc2Out array into a single 1xN array.  The dense layers expect a 1D thing\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        # print(\"after flatten \" + str(x.shape))\n",
    "        # x = x.view(x.shape[0], -1)  #equivalent ways of reshaping the data to be 1D\n",
    "        # x = x.view(batch_size( x.shape[0]) , -1)\n",
    "        # print(\"after x = x.view(-1, self.num_flat_features(x)) \" + str(x.shape))\n",
    "        \n",
    "        # x = F.relu(self.fc1(x)) #apply dense layer 1\n",
    "        x = self.fc1(x)\n",
    "        # print(\"dense layer1 \" + str(x.shape))\n",
    "        x = F.relu(x)\n",
    "        # print(x.shape)\n",
    "        # x = F.relu(self.fc2(x)) #and dense layer 2, using ReLU activation\n",
    "        x = self.fc2(x)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        # print(x.shape)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    #compute the output size after our convolution layers\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, tensor_train):\n",
    "    criterion = nn.CrossEntropyLoss() #this is a way of measuring error for classification that takes the\n",
    "    #\"confidence\" of a prediction into account.  High confidence, correct predictions are low cost, \n",
    "    #high confidence, wrong predictions are high cost, medium confidence predictions have cost\n",
    "\n",
    "    #use the ADAM optimizer to find the best weights\n",
    "    optimizer = optim.Adam(model.parameters(), lr= 1e-4) \n",
    "    \n",
    "    #this loads data and gets it in the right format for us\n",
    "    trainloader = torch.utils.data.DataLoader(tensor_train, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            \n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs) #predict the output with some training data\n",
    "            loss = criterion(outputs, labels.to(torch.long)) #see how well we did\n",
    "            loss.backward() #see how to change the weights to do better\n",
    "            optimizer.step() #and actually change the weights\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "def evaluate(model, tensor_test):  \n",
    "    #load some test data\n",
    "    testloader = torch.utils.data.DataLoader(tensor_test, batch_size=8,\n",
    "                                                shuffle=True, num_workers=0)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    #just do a coarse evaluation... how many did we predict correcly?\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 7 %\n"
     ]
    }
   ],
   "source": [
    "train(net, 8, tensor_train)\n",
    "evaluate(net, tensor_test)"
   ]
  },
  {
   "source": [
    "The accuracy of the network seems to be between 11% - 22% after running it multiple times. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NxtNet(nn.Module):\n",
    "    def __init__(self, uniqueChars):\n",
    "        super(NxtNet, self).__init__()\n",
    "        c1Out = 10 # convoluation layer 1 will output 6 \"images\": one for each filter it trains\n",
    "        c2Out = 20 # similarly for the 2nd convolution layer\n",
    "        self.conv1 = nn.Conv2d(1, c1Out, 3) #1-D input, c1Out outputs, filter size 3x3 pixels\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2) #downsample 2x2 blocks to 1 value\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(c1Out, c2Out, 3) #inputs comes from conv1 , specify our #outputs, use 3x3 \n",
    "        self.conv2_norm = nn.BatchNorm2d(20)\n",
    "        self.pooledOutputSize = c2Out*3*3 \n",
    "        self.fc1 = nn.Linear(self.pooledOutputSize, 240)\n",
    "        self.fc2 = nn.Linear(240, uniqueChars)\n",
    "\n",
    "    def forward(self, x): # \"batch\" of images\n",
    "        #x is 4D tensor:  (batch size, width, height, #channels (1, grayscale image))\n",
    "        #after conv1:  (batch size, width adjusted, height adjusted, conv1 # outputs)\n",
    "        #after max pool: (batch size, width/2, height/2, conv1 # outputs)\n",
    "        # print(\"Before 1st: \" + str(x.shape))\n",
    "        # x = F.relu(self.conv1(x))\n",
    "        x = self.conv1(x)\n",
    "        # print(\"x = self.conv1(x) \" + str(x.shape))\n",
    "        x = F.relu(x)\n",
    "        # print(\"x = F.relu(x) \" + str(x.shape))\n",
    "        x = self.pool(x)\n",
    "        # print(\"Max Pool: \" + str(x.shape))\n",
    "        #split into 2 lines above\n",
    "        #x = self.pool(F.relu(self.conv1(x)))  #apply convolution filter, then run it through relu activation function\n",
    "        # x = self.pool(F.relu(self.conv2(x))) #ditto\n",
    "        x = self.conv2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.conv2_norm(x)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        # print(\"after pool before flatten \" + str(x.shape))\n",
    "        #print(x.shape) #uncomment to see the size of this layer.  It helped me figure out what pooledOutputSize shoudl be\n",
    "        \n",
    "        \n",
    "        #turn the 5x5xc2Out array into a single 1xN array.  The dense layers expect a 1D thing\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        # print(\"after flatten \" + str(x.shape))\n",
    "        # x = x.view(x.shape[0], -1)  #equivalent ways of reshaping the data to be 1D\n",
    "        # x = x.view(batch_size( x.shape[0]) , -1)\n",
    "        # print(\"after x = x.view(-1, self.num_flat_features(x)) \" + str(x.shape))\n",
    "        \n",
    "        # x = F.relu(self.fc1(x)) #apply dense layer 1\n",
    "        x = self.fc1(x)\n",
    "        # print(\"dense layer1 \" + str(x.shape))\n",
    "        x = F.relu(x)\n",
    "        # print(x.shape)\n",
    "        # x = F.relu(self.fc2(x)) #and dense layer 2, using ReLU activation\n",
    "        x = self.fc2(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "    \n",
    "    #compute the output size after our convolution layers\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "nxtnet = NxtNet(uniqueChars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 49 %\n"
     ]
    }
   ],
   "source": [
    "train(nxtnet, 20, tensor_train)\n",
    "evaluate(nxtnet, tensor_test)"
   ]
  },
  {
   "source": [
    "Adding batch normalization to the 2nd convolution increased accuracy from 18% to 50%"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        font fontVariant  m_label  strength  italic  orientation  m_top  \\\n",
       "0     AGENCY   AGENCY FB    64258       0.4       0          0.0     35   \n",
       "1     AGENCY   AGENCY FB    64257       0.4       0          0.0     35   \n",
       "2     AGENCY   AGENCY FB    61442       0.4       0          0.0     35   \n",
       "3     AGENCY   AGENCY FB    61441       0.4       0          0.0     35   \n",
       "4     AGENCY   AGENCY FB     9674       0.4       0          0.0     51   \n",
       "...      ...         ...      ...       ...     ...          ...    ...   \n",
       "999   AGENCY   AGENCY FB       37       0.7       1          0.0     35   \n",
       "1000  AGENCY   AGENCY FB       36       0.7       1          0.0     30   \n",
       "1001  AGENCY   AGENCY FB       35       0.7       1          0.0     35   \n",
       "1002  AGENCY   AGENCY FB       34       0.7       1          0.0     35   \n",
       "1003  AGENCY   AGENCY FB       33       0.7       1          0.0     35   \n",
       "\n",
       "      m_left  originalH  originalW  ...  r19c10  r19c11  r19c12  r19c13  \\\n",
       "0         21         51         22  ...       1       1       1       1   \n",
       "1         21         51         22  ...       1       1       1       1   \n",
       "2         21         51         22  ...       1       1       1       1   \n",
       "3         21         51         22  ...       1       1       1       1   \n",
       "4         21         33         25  ...     255     132       1       1   \n",
       "...      ...        ...        ...  ...     ...     ...     ...     ...   \n",
       "999       27         51         48  ...     255     255     255     231   \n",
       "1000      24         61         40  ...       1       1       1       1   \n",
       "1001      25         51         44  ...       1       1       1       1   \n",
       "1002      35         16         21  ...     255     255     255     255   \n",
       "1003      23         51         25  ...       1       1       1       1   \n",
       "\n",
       "      r19c14  r19c15  r19c16  r19c17  r19c18  r19c19  \n",
       "0          1       1     163     255     255     255  \n",
       "1          1       1     163     255     255     255  \n",
       "2          1       1     163     255     255     255  \n",
       "3          1       1     163     255     255     255  \n",
       "4          1       1       1       1       1       1  \n",
       "...      ...     ...     ...     ...     ...     ...  \n",
       "999      114       1       1       1       1       1  \n",
       "1000       1       1       1       1       1       1  \n",
       "1001       1       1       1       1       1       1  \n",
       "1002      73       1       1       1       1       1  \n",
       "1003       1       1       1       1       1       1  \n",
       "\n",
       "[1004 rows x 412 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>font</th>\n      <th>fontVariant</th>\n      <th>m_label</th>\n      <th>strength</th>\n      <th>italic</th>\n      <th>orientation</th>\n      <th>m_top</th>\n      <th>m_left</th>\n      <th>originalH</th>\n      <th>originalW</th>\n      <th>...</th>\n      <th>r19c10</th>\n      <th>r19c11</th>\n      <th>r19c12</th>\n      <th>r19c13</th>\n      <th>r19c14</th>\n      <th>r19c15</th>\n      <th>r19c16</th>\n      <th>r19c17</th>\n      <th>r19c18</th>\n      <th>r19c19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AGENCY</td>\n      <td>AGENCY FB</td>\n      <td>64258</td>\n      <td>0.4</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>21</td>\n      <td>51</td>\n      <td>22</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>163</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AGENCY</td>\n      <td>AGENCY FB</td>\n      <td>64257</td>\n      <td>0.4</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>21</td>\n      <td>51</td>\n      <td>22</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>163</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AGENCY</td>\n      <td>AGENCY FB</td>\n      <td>61442</td>\n      <td>0.4</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>21</td>\n      <td>51</td>\n      <td>22</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>163</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AGENCY</td>\n      <td>AGENCY FB</td>\n      <td>61441</td>\n      <td>0.4</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>21</td>\n      <td>51</td>\n      <td>22</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>163</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AGENCY</td>\n      <td>AGENCY FB</td>\n      <td>9674</td>\n      <td>0.4</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>51</td>\n      <td>21</td>\n      <td>33</td>\n      <td>25</td>\n      <td>...</td>\n      <td>255</td>\n      <td>132</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>AGENCY</td>\n      <td>AGENCY FB</td>\n      <td>37</td>\n      <td>0.7</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>27</td>\n      <td>51</td>\n      <td>48</td>\n      <td>...</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>231</td>\n      <td>114</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1000</th>\n      <td>AGENCY</td>\n      <td>AGENCY FB</td>\n      <td>36</td>\n      <td>0.7</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>30</td>\n      <td>24</td>\n      <td>61</td>\n      <td>40</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1001</th>\n      <td>AGENCY</td>\n      <td>AGENCY FB</td>\n      <td>35</td>\n      <td>0.7</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>25</td>\n      <td>51</td>\n      <td>44</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1002</th>\n      <td>AGENCY</td>\n      <td>AGENCY FB</td>\n      <td>34</td>\n      <td>0.7</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>35</td>\n      <td>16</td>\n      <td>21</td>\n      <td>...</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>73</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1003</th>\n      <td>AGENCY</td>\n      <td>AGENCY FB</td>\n      <td>33</td>\n      <td>0.7</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>35</td>\n      <td>23</td>\n      <td>51</td>\n      <td>25</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1004 rows × 412 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "book_data = pd.read_csv(\"AGENCY.csv\")\n",
    "book_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data = book_data.drop(columns=['font', 'fontVariant', 'strength', 'italic', 'orientation', 'm_top', 'm_left', 'originalH', 'originalW', 'h', 'w'])\n",
    "book_pixel_values = book_data.drop(columns=['m_label'])\n",
    "book_pixel_array = np.array(book_pixel_values)\n",
    "book_pixel_array = book_pixel_array.astype(float)\n",
    "for i in range(len(book_pixel_array)):\n",
    "    for j in range(len(book_pixel_array[0])):\n",
    "        book_pixel_array[i][j] = book_pixel_array[i][j] / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([209, 208,   1, ...,  22, 224, 219])"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "Xs = book_pixel_array # 20 x 20 array containing the pixel values\n",
    "Xs = np.reshape(Xs, (-1, 1, 20, 20))\n",
    "book_chars = set(book_data['m_label'])\n",
    "uniqueChars = len(book_chars)\n",
    "char_to_ix = {char: i for i, char in enumerate(book_chars)}\n",
    "asciiValues = book_data['m_label']\n",
    "lst = []\n",
    "for ascii_val in asciiValues:\n",
    "    lst.append(char_to_ix[ascii_val]) # creating list of index values of each ascii char label\n",
    "\n",
    "Ys = np.array(lst) # convert list to numpy array\n",
    "Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into testing and training sets\n",
    "Xs_train, Xs_test, Ys_train, Ys_test = train_test_split(Xs, Ys, random_state=1, test_size=0.75)\n",
    "Xs_train = torch.tensor(Xs_train, dtype = torch.float)\n",
    "Ys_train = torch.tensor(Ys_train, dtype = torch.float)\n",
    "Xs_test = torch.tensor(Xs_test, dtype = torch.float)\n",
    "Ys_test = torch.tensor(Ys_test, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_test = TensorDataset(Xs_test, Ys_test) \n",
    "tensor_train = TensorDataset(Xs_train, Ys_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished Training\nAccuracy of the network on the 10000 test images: 11 %\n"
     ]
    }
   ],
   "source": [
    "train(nxtnet, 20, tensor_train)\n",
    "evaluate(nxtnet, tensor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished Training\nAccuracy of the network on the 10000 test images: 0 %\n"
     ]
    }
   ],
   "source": [
    "train(net, 20, tensor_train)\n",
    "evaluate(net, tensor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestNet = nxtnet\n",
    "f = pd.read_csv('AGENCY.csv')\n",
    "f2 = pd.read_csv('BRUSH.csv')\n",
    "f3 = pd.read_csv('BOOK.csv')\n",
    "data1 = f.loc[:, 'r0c0':]\n",
    "data2 = f2.loc[:, 'r0c0':]\n",
    "data3 = f3.loc[:, 'r0c0':]\n",
    "\n",
    "mixed_fonts_labels = pd.concat([f['m_label'], f2['m_label'], f3['m_label']]).reset_index(drop=True)\n",
    "mixed_fonts = pd.concat([data1, data2, data3]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4628,)\n(4628, 1, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "Xs = np.array(mixed_fonts)\n",
    "Xs = Xs.astype(float)\n",
    "for i in range(len(Xs)):\n",
    "    for j in range(len(Xs[0])):\n",
    "        Xs[i][j] = Xs[i][j] / 256\n",
    "Xs = np.reshape(Xs, (-1, 1, 20, 20))\n",
    "chars = set(mixed_fonts_labels)\n",
    "uniqueChars = len(chars)\n",
    "char_to_ix = {char: i for i, char in enumerate(chars)}\n",
    "asciiValues = mixed_fonts_labels\n",
    "lst = []\n",
    "for ascii_val in asciiValues:\n",
    "    lst.append(char_to_ix[ascii_val]) # creating list of index values of each ascii char label\n",
    "\n",
    "Ys_mixed = np.array(lst) # convert list to numpy array\n",
    "Xs_mixed = Xs\n",
    "print(Ys_mixed.shape)\n",
    "print(Xs_mixed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_mixed_train, Xs_mixed_test, Ys_mixed_train, Ys_mixed_test = train_test_split(Xs_mixed[:-len(f3)], Ys_mixed[:-len(f3)])\n",
    "Xs_mixed_train = torch.tensor(Xs_mixed_train, dtype = torch.float)\n",
    "Ys_mixed_train = torch.tensor(Ys_mixed_train, dtype = torch.float)\n",
    "Xs_mixed_test = torch.tensor(Xs_mixed_test, dtype = torch.float)\n",
    "Ys_mixed_test = torch.tensor(Ys_mixed_test, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_mixed_test = TensorDataset(Xs_mixed_test, Ys_mixed_test) \n",
    "tensor_mixed_train = TensorDataset(Xs_mixed_train, Ys_mixed_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished Training\nAccuracy of the network on the 10000 test images: 48 %\n"
     ]
    }
   ],
   "source": [
    "best_network_mixed = NxtNet(uniqueChars\n",
    "\n",
    "\n",
    "train(best_network_mixed, 20, tensor_mixed_train)\n",
    "evaluate(best_network_mixed, tensor_mixed_test)\n"
   ]
  },
  {
   "source": [
    "Accuracy increased from 11% - 48% using the multiple font set instead of 1 font"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}